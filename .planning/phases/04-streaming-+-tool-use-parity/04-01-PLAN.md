---
phase: 04-streaming-+-tool-use-parity
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - src/transport/openai_stream.py
  - src/transport/__init__.py
autonomous: true
must_haves:
  truths:
    - "OpenAI Responses streaming frames can be consumed as parsed SSE events"
    - "Streaming requests forward correlation IDs to the upstream"
  artifacts:
    - path: "src/transport/openai_stream.py"
      provides: "Async streaming client that yields parsed SSE events"
    - path: "src/transport/__init__.py"
      provides: "Exports streaming transport for handlers"
  key_links:
    - from: "src/transport/openai_stream.py"
      to: "src/config.py"
      via: "require_openai_api_key + OPENAI_BASE_URL"
      pattern: "require_openai_api_key\(|OPENAI_BASE_URL"
    - from: "src/transport/openai_stream.py"
      to: "X-Correlation-ID header"
      via: "asgi_correlation_id"
      pattern: "X-Correlation-ID"
---

<objective>
Build the upstream streaming transport that parses OpenAI SSE frames into structured events.

Purpose: Provide a reliable, correlation-aware source of streaming events for the Anthropic SSE translator.
Output: Async generator that yields parsed SSE events for `/v1/messages/stream`.
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/04-streaming-+-tool-use-parity/04-RESEARCH.md
@src/transport/openai_client.py
@src/config.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add OpenAI streaming transport with SSE parsing</name>
  <files>src/transport/openai_stream.py</files>
  <action>
Create a new streaming transport module that exposes an async generator `stream_openai_events(payload: Dict[str, Any])`.

- Clone the auth + header behavior from `create_openai_response` (use `require_openai_api_key`, `OPENAI_BASE_URL`, and forward `X-Correlation-ID` from `asgi_correlation_id`).
- Ensure `payload["stream"] = True` before sending the request.
- Use `httpx.AsyncClient.stream("POST", url, json=payload, headers=headers)` and iterate `response.aiter_lines()`.
- If `response.is_error`, raise `OpenAIUpstreamError` with a safe JSON payload (local `_safe_json` helper is fine; do NOT rely on private helpers).
- Implement minimal SSE parsing:
  - Track current `event` and `data` lines until a blank line, then emit a dict like `{ "event": "...", "data": parsed }`.
  - Default event name to "message" if none provided.
  - Join multi-line `data:` segments with "\n".
  - Parse `data` as JSON when possible; fallback to raw string.
  - Ignore comment/keepalive lines beginning with `:`.
- Yield only completed events; keep the generator resilient to `ping` events and unknown event types.
  </action>
  <verify>python -m compileall src</verify>
  <done>Streaming transport yields parsed SSE event dicts and raises OpenAIUpstreamError on upstream failures.</done>
</task>

<task type="auto">
  <name>Task 2: Export streaming transport from transport package</name>
  <files>src/transport/__init__.py</files>
  <action>
Export the new `stream_openai_events` function alongside existing transport exports so handlers can import it from `src.transport`.
  </action>
  <verify>python -m compileall src</verify>
  <done>`stream_openai_events` is importable via `from src.transport import stream_openai_events`.</done>
</task>

</tasks>

<verification>
- `python -m compileall src` succeeds.
</verification>

<success_criteria>
- Upstream streaming requests can be made with correlation IDs forwarded and SSE frames parsed into structured events.
</success_criteria>

<output>
After completion, create `.planning/phases/04-streaming-+-tool-use-parity/04-01-SUMMARY.md`
</output>
